# Advanced Parameters

We expose a number of more advanced environment variables to assist with tuning for different workloads.

One of the first concepts to become familiar with is the structure for how rindexer controls concurrency
across events and networks. By nature of indexing and rpc nodes, we must index separately per network, however
we also try to optimize throughput via `eth_getLogs` requests per event. This means we ultimately run a sub-indexing
process per "network-event".

This "network-event" is where concurrency is controlled.

## Parameters

### `RINDEXER_CHANNEL_SIZE`

_Default: `4`_

This env controls buffer of events we will hold in memory, per "network-event". This is extremely useful for
controlling an upper memory bound during large scale backfill operations for high-frequency events (like ERC20 transfers).

What happens if the handler does not release events as fast as they can queried? Well,a backlog of events we've indexed
would build up in memory and ultimately the process would OOM and be killed.

We avoid that by maintaining a bounded channel (buffer) of events. This way when the handler is ready it will pull the
next event, and it will trigger a new indexing fetch to fill the freed slot.

The default should be enough to balance memory use with high-throughput, however can be tweaked to constrain memory by
lowering the value. Or potentially increasing throughput by increasing the value.

:::info
This concept is known as "back-pressuring".
:::


### `RINDEXER_EVENT_CONCURRENCY`

_Default: `2`_

This env controls the per "network-event" handler callback rate.

When "index_event_in_order" is enabled for an event, it will always override any value with `1` to ensure consistent
FIFO ordering.

The default for all other cases is `2` which means we can have two concurrent handlers being called per "network event".
This may or may not be desirable based on the use-case and code present in the handler callback function.

A case where this may not be desirable is if there is any kind of "per network-event global locking" which would mean that
trying to run 2 batches in parallel would simply result in one batch holding the other up.

The other extreme would be setting this to some very high number `999999` representing unbounded concurrency. In this case
you can imagine that there is essentially no "back-pressure". This would work in the case where events are simply being
discarded, being maintained in memory, or some other hyper-efficient mechanism.

In reality, the most common case for indexing will be to persist the events to a database, and in these cases there are
factors such as networking time, data structure locks, database connection pool limits, and resource constraints.

This means we cannot reasonably benefit from increasing this number and on the contrary can suffer a decrease in throughput
due to lock contention, and unwanted situations like connection pool exhaustion, deadlocks, and more.

You may benefit from increasing this above `2` for very simple workloads.